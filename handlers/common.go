package handlers

import (
	"github.com/ValeryVerkhoturov/chat/utils/arxivApi"
	"github.com/ValeryVerkhoturov/chat/utils/formatting"
	"github.com/ValeryVerkhoturov/chat/utils/yandexCloudApi"
	"github.com/gin-gonic/gin"
	log "github.com/sirupsen/logrus"
	"net/http"
	"strconv"
	"strings"
)

func Index(c *gin.Context) {
	c.HTML(http.StatusOK, "index.html", TemplateData{
		HeaderTitle: "Index docs",
		NavbarTitle: formatting.NewNavbarTitle(formatting.Index),
	})
}

func Generate(c *gin.Context) {
	c.HTML(http.StatusOK, "generate.html", TemplateData{
		HeaderTitle: "Generate text",
		NavbarTitle: formatting.NewNavbarTitle(formatting.Generate),
	})
}

func ResetIndex(c *gin.Context) {
	c.HTML(http.StatusOK, "reset-index.html", TemplateData{
		HeaderTitle: "Reset index",
		NavbarTitle: formatting.NewNavbarTitle(formatting.ResetIndex),
	})
}

func Help(c *gin.Context) {
	c.HTML(http.StatusOK, "help.html", TemplateData{
		HeaderTitle: "Help",
		NavbarTitle: formatting.NewNavbarTitle(formatting.Help),
	})
}

func NotFound(c *gin.Context) {
	c.HTML(http.StatusNotFound, "404.html", TemplateData{
		HeaderTitle: "404",
	})
}

func ProcessQuery(c *gin.Context) {
	query := c.PostForm("query")
	page, err := strconv.Atoi(c.PostForm("page"))
	if page < 1 || err != nil {
		page = 1
	}
	if len(query) == 0 {
		c.HTML(http.StatusOK, "file-search-list.html", &TemplateData{Error: "Empty query"})
		return
	}

	feed, err := arxivApi.Query(query, page)
	if err != nil {
		c.HTML(http.StatusOK, "file-search-list.html", &TemplateData{Error: err.Error()})
		return
	}

	c.HTML(http.StatusOK, "file-search-list.html", TemplateData{Pagination: Pagination{Page: page, PreviousPage: page - 1, NextPage: page + 1}, Query: query, Data: feed})
}

func AppendToIndex(c *gin.Context) {
	href := c.PostForm("href")
	if len(href) == 0 || !strings.HasPrefix(href, "http://arxiv.org/pdf/") {
		c.String(http.StatusOK, "<span class=\"text-red-500 hover:text-red-600\">Invalid link</span>")
		return
	}

	err := appendToIndex(href)
	if err != nil {
		c.String(http.StatusOK, "<span class=\"text-red-500 hover:text-red-600\">Index error</span>")
		return
	}

	c.String(http.StatusOK, "<span class=\"text-green-500 hover:text-green-600\">Success index</span>")
}

func appendToIndex(href string) error {
	pdfContent, err := arxivApi.DownloadPdf(href)
	if err != nil {
		return err
	}

	// text := "\"Spark NLP: Natural Language Understanding at Scale\nVeysel Kocaman, David Talby\nJohn Snow Labs Inc.\n16192 Coastal Highway\nLewes, DE, USA 19958\n{veysel, david/@ johnsnowlabs.com\nAbstract\nSpark NLP is a Natural Language Processing (NLP) library built on top of\nApache Spark ML. It provides simple, performant \\u0026 accurate NLP annotations\nfor machine learning pipelines that can scale easily in a distributed environment.\nSpark NLP comes with 1100+ pretrained pipelines and models in more than 192+\nlanguages. It supports nearly all the NLP tasks and modules that can be used seam-\nlessly in a cluster. Downloaded more than 2.7 million times and experiencing 9x\ngrowth since January 2020, Spark NLP is used by 54% of healthcare organizations\nas the world's most widely used NLP library in the enterprise.\nKeywords: spark, natural language processing, deep learning, tensorflow, cluster\n1. Spark NLP Library\nNatural language processing (NLP) is a key component in many data science\nsystems that must understand or reason about a text. Common use cases include\nquestion answering, paraphrasing or summarising, sentiment analysis, natural\nlanguage BI, language modelling, and disambiguation. Nevertheless, NLP is\nalways just a part of a bigger data processing pipeline and due to the nontrivial\nsteps involved in this process, there is a growing need for all-in-one solution to ease\nthe burden of text preprocessing at large scale and connecting the dots between\nvarious steps of solving a data science problem with NLP. A good NLP library\nshould be able to correctly transform the free text into structured features and\nlet the users train their own NLP models that are easily fed into the downstream\nmachine learning (ML) or deep learning (DL) pipelines with no hassle.\nSpark NLP is developed to be a single unified solution for all the NLP tasks\nand is the only library that can scale up for training and inference in any Spark\ncluster, take advantage of transfer learning and implementing the latest and greatest\nPreprint submitted to Software Impacts\nJanuary 27, 2021\nalgorithms and models in NLP research, and deliver a mission-critical, enterprise-\ngrade solutions at the same time. It is an open-source natural language processing\nlibrary, built on top of Apache Spark and Spark ML. It provides an easy API to\nintegrate with ML pipelines and it is commercially supported by John Snow Labs\nInc, an award-winning healthcare AI and NLP company based in USA.\nSpark NLP's annotators utilize rule-based algorithms, machine learning and\ndeep learning models which are implemented using TensorFlow that has been\nheavily optimized for accuracy, speed, scalability, and memory utilization. This\nsetup has been tightly integrated with Apache Spark to let the driver node run the\nentire training using all the available cores on the driver node. There is a CuDA\nversion of each TensorFlow component to enable training models on GPU when\navailable. The Spark NLP is written in Scala and provides open-source API's in\nPython, Java, Scala, and R - so that users do not need to be aware of the underlying\nimplementation details (TensorFlow, Spark, etc.) in order to use it. Since it has\nan active release cycle (released 26 new versions in 2019 and another 26 in 2020),\nthe latest trends and research in NLP field are embraced and implemented rapidly\nin a way that could scale well in a cluster setting to allow common NLP pipelines\nrun orders of magnitude faster than what the inherent design limitations of legacy\nlibraries allowed.\nSpark NLP library has two versions: Open source and enterprise. Open source\nversion has all the features and components that could be expected from any NLP\nlibrary, using the latest DL frameworks and research trends. Enterprise library is\nlicensed (free for academic purposes) and designed towards solving real world\nproblems in healthcare domain and extends the open source version. The licensed\nversion has the following modules to help researchers and data practitioners in\nvarious means: Named entity recognition (NER), assertion status (negativity scope)\ndetection, relation extraction, entity resolution (SNOMED, RxNorm, ICD10 etc.),\nclinical spell checking, contextual parser, text2SQL, deidentification and obfus-\ncation. High level overview of the components from each version can be seen at\nFigure 4.\n2. The impact to research fields\nThe COVID-19 pandemic brought a surge of academic research about the\nvirus - resulting in 23,634 new publications between January and June of 2020\n[1] and accelerating to 8,800 additions per week from June to November on the\nCOVID-19 Open Research Dataset [2]. Such a high volume of publications makes\nit impossible for researchers to read each publication, resulting in increased interest\nin applying natural language processing (NLP) and text mining techniques to\nenable semi-automated literature review [3].\n2\nIn parallel, there is a growing need for automated text mining of Electronic\nhealth records (EHRs) in order to find clinical indications that new research points\nto. EHRs are the primary source of information for clinicians tracking the care\nof their patients. Information fed into these systems may be found in structured\nfields for which values are inputted electronically (e.g. laboratory test orders or\nresults) [4] but most of the time information in these records is unstructured making\nit largely inaccessible for statistical analysis [5]. These records include information\nsuch as the reason for administering drugs, previous disorders of the patient or\nthe outcome of past treatments, and they are the largest source of empirical data\nin biomedical research, allowing for major scientific findings in highly relevant\ndisorders such as cancer and Alzheimer's disease [6]. Despite the growing interest\nand ground breaking advances in NLP research and NER systems, easy to use\nproduction ready models and tools are scarce in biomedical and clinical domain\nand it is one of the major obstacles for clinical NLP researchers to implement\nthe latest algorithms into their workflow and start using immediately. On the\nother hand, NLP tool kits specialized for processing biomedical and clinical text,\nsuch as MetaMap [7] and cTAKES [8] typically do not make use of new research\ninnovations such as word representations or neural networks discussed above,\nhence producing less accurate results [9, 10]. We introduce Spark NLP as the\none-stop solution to address all these issues.\nA primary building block in such text mining systems is named entity recogni-\ntion (NER) - which is regarded as a critical precursor for question answering, topic\nmodelling, information retrieval, etc [11]. In the medical domain, NER recognizes\nthe first meaningful chunks out of a clinical note, which are then fed down the\nprocessing pipeline as an input to subsequent downstream tasks such as clinical\nassertion status detection [12], clinical entity resolution [13] and de-identification\nof sensitive data [14]. However, segmentation of clinical and drug entities is\nconsidered to be a difficult task in biomedical NER systems because of complex\northographic structures of named entities [15]. Sample NER predictions from\na\nclinical text can be found at Figure 3.\nThe next step following an NER model in the clinical NLP pipeline is to\nassign an assertion status to each named entity given its context. The status of an\nassertion explains how a named entity (e.g. clinical finding, procedure, lab result)\npertains to the patient by assigning a label such as present (\\\"patient is diabetic\\\"),\nabsent (\\\"patient denies nausea\\\"), conditional (\\\"dyspnea while climbing stairs\\\"),\nor associated with someone else (\\\"family history of depression\\\"). In the context\nof COVID-19, applying an accurate assertion status detection is crucial, since\nmost patients will be tested for and asked about the same set of symptoms and\ncomorbidities - so limiting a text mining pipeline to recognizing medical terms\nwithout context is not useful in practice. The flow diagram of such a pipeline can\nbe seen in Figure [1.\n3\nIn our previous study [16], we showed through extensive experiments that\nNER module in Spark NLP library exceeds the biomedical NER benchmarks\nreported by Stanza in 7 out of 8 benchmark datasets and in every dataset reported\nby SciSpacy without using heavy contextual embeddings like BERT. Using the\nmodified version of the well known BiLSTM-CNN-Char NER architecture [17]\ninto Spark environment, we also presented that even with a general purpose GloVe\nembeddings (GloVe6B) and with no lexical features, we were able to achieve state-\nof-the-art results in biomedical domain and produces better results than Stanza in 4\nout of 8 benchmark datasets.\nIn another study [18], we introduced a set of pre-trained NER models that\nare all trained on biomedical and clinical datasets using the same deep learning\narchitecture. We then illustrated how to extract knowledge and relevant information\nfrom unstructured electronic health records (EHR) and COVID-19 Open Research\nDataset (CORD-19) by combining these models in a unified \\u0026 scalable pipeline\nand shared the results to illustrate extracting valuable information from scientific\npapers. The results suggest that papers present in the CORD-19 include a wide\nvariety of the many entity types that this new NLP pipeline can recognize, and\nthat assertion status detection is a useful filter on these entities (Figure 2). The\nmost frequent phrases from the selected entity types can be found at Table 2. This\nbodes well for the richness of downstream analysis that can be done using this\nnow structured and normalized data - such as clustering, dimensionality reduction,\nsemantic similarity, visualization, or graph-based analysis to identity correlated\nconcepts. Moreover, in order to evaluate how fast the pipeline works and how\neffectively it scales to make use of a compute cluster, we ran the same Spark\nNLP prediction pipelines in local mode and in cluster mode: and found out that\ntokenization is 20x faster while the entity extraction is 3.5x faster on the cluster,\ncompared to the single machine run.\n3. The impact to industrial and academic collaborations\nAs the creator of Spark NLP, John Snow Labs company has been supporting\nthe researchers around the globe by distributing them a free license to use all the\nlicensed modules both in research projects and graduate level courses at universities,\nproviding hands-on supports when needed, organizing workshops and summits\nto gather distinguished speakers and running projects with the R\\u0026D teams of the\ntop pharmacy companies to help them unlock the potential of unstructured text\ndata buried in their ecosystem. Spark NLP already powers leading healthcare and\npharmaceutical companies including Kaiser Permanente, McKesson, Merck, and\nRoche. Since Spark NLP can also be used offline and deployed in air-gapped\nnetworks, the companies and healthcare facilities do not need to worry about\n4\nexposing the protected health information (PHI). The detailed information about\nthese projects and case studies can be found at [19], [20], [21].\nDocumentAssembler()\nSentenceDetector()\nTokenizer()\nNormalizer()\nWordEmbeddings()\ntext\ntext\ndocument\ntext\ndocument\nsentences\ntext\ndocument\nsentences\ntoker\ntext\ndocument\nsentences\ntoken\nnormal\ntext\ndocument\nsentences\ntoken\nnormal\nembeddings\nDataFrame\nFigure 1: The flow diagram of a Spark NLP pipeline. When we fit() on the pipeline with a Spark\ndata frame, its text column is fed into the DocumentAssembler() transformer and a new column\ndocument is created as an initial entry point to Spark NLP for any Spark data frame. Then, its\ndocument column is fed into the SentenceDetector() module to split the text into an array of\nsentences and a new column \\\"sentences\\\" is created. Then, the \\\"sentences\\\" column is fed into\nTokenizer(), each sentence is tokenized, and a new column \\\"token\\\" is created. Then, Tokens are\nnormalized (basic text cleaning) and word embeddings are generated for each. Now data is ready to\nbe fed into NER models and then to the assertion model.\nTable 1: NER performance across different datasets in the biomedical domain. All scores reported\nare micro-averaged test F1 excluding O's. Stanza results are from the paper reported in [9],\nSciSpaCy results are from the scispacy-medium models reported in [10]. The official training and\nvalidation sets are merged and used for training and then the models are evaluated on the original\ntest sets. For reproducibility purposes, we use the preprocessed versions of these datasets provided\nby [22] and also used by Stanza. Spark-x prefix in the table indicates our implementation. Bold\nscores represent the best scores in the respective row.\nSpark\n-\nDataset\nEntities\nSpark - GloVe 6B Stanza SciSpacy\nBiomedical\nNCBI-Disease\nDisease\nBC5CDR\nChemical, Disease\nBC4CHEMD Chemical\nLinnaeus\nSpecies\nSpecies800\nSpecies\nJNLPBA\n5 types in cellular\nAnatEM\nAnatomy\nBioNLP13-CG 16 types in Cancer Genetics\n89.13\n89.73\n93.72\n86.26\n80.91\n81.29\n89.13\n85.58\n87.19\n88.32\n92.32\n85.51\n79.22\n79.78\n87.74\n84.30\n87.49 81.65\n88.08 83.92\n89.65 84.55\n88.27 81.74\n76.35 74.06\n76.09 73.21\n88.18\n84.14\n84.34\n77.60\n4. Acknowledgements\nWe thank our colleagues and research partners who contributed in the former\nand current developments of Spark NLP library. We also thank our users and\ncustomers who helped us improve the library with their feedbacks and suggestions.\n5\nClinical\nEntity Recognition\n40 units DOSAGE of\ninsulin glargine DRUG\nat night FREQUENCY\nClinical\nEntity Linking\nAssertion Status\nDe-Identification\nRelation Extraction\nAFTER\nSuspect diabetes SNOMED-CT: 473127005\nLisinopril 10 MG RxNorm: 316151\nPyponatremia ICD-10: E87.1\nFever and sore throat -\\u003e PRESENT\nNo stomach pain -\\u003e ABSENT\nFather with Alzheimer -\\u003e FAMILY\nOra NaMe,a 25 agE yo\ncashier PROFESSION from\nMorocco LOCATION\nAdmitted for nausea dueto chemo\nOccurrence\nSymptom\nTreatment\nCAUSED BY\nA 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years\nprior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode\nof HTG-induced pancreatitis three years prior to presentation , associated with an acute\nhepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-\nweek history of polyuria, polydipsia , poor appetite , and vomiting . Two weeks prior to\nThe patient was prescribed 1 capsule of Advil for 5 days . He was seen by the endocrinology\nservice and she was discharged on 40 units of insulin glargine at night, 12 units of insulin\nlispro with meals , and metformin 1000 mg two times a day . It was determined that all\nSGLT2 inhibitors should be discontinued indefinitely fro 3 months .\npresentation , she was treated with a five-day course of amoxicillin for a respiratory tract\ninfection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and\ngemfibrozil for HTG . She had been on dapagliflozin for six months at the time of\npresentation . Physical examination on presentation was significant for dry oral mucosa ;\nsignificantly, her abdominal examination was benign with no tenderness , guarding , or\nrigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl\nbicarbonate 18 mmol/l, anion gap 20 , creatinine 0.4 mg/dL, triglycerides 508 mg/dL, total\ncholesterol 122 mg/dL, glycated hemoglobin ( HbA1c) 10% , and venous pH 7.27 . Serum\nlipase was normal at 43 U/L. Serum acetone levels could not be assessed as blood samples\nkept hemolyzing due to significant lipemia . The patient was initially admitted for starvation\nketosis , as she reported poor oral intake for three days prior to admission . However , serum\nchemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the\nanion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level\npeaked at 2050 mg/dL, and lipase was 52 U/L. The B-hydroxybutyrate level was obtained\nand found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the\nchylomicron layer removed prior to analysis due to interference from turbidity caused by\nlipemia again .\nColor codes: FREQUENCY DOSAGE, DURATION, DRUG, FORM, STRENGTH, Posology NER\nNo findings in urinary system , skin color is normal , brain CT and cranial checks are clear .\nSwollen fingers and eyes . Extensive stage small cell lung cancer . Chemotherapy with\ncarboplatin and etoposide . Left scapular pain status post CT scan of the thorax .\nColor codes:Organ, Organism_subdivision, Organism_substance, Pathological_formation,\nAnatomical_system,\nAnatomy NER\nA. Record date : 2093-01-13 , David Hale , M.D., Name : Hendrickson , Ora MR. # 7194334\nDate : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09 . Cocke County\nBaptist Hospital . 0295 Keats Street\nClinical NER\nColor codes:STREET, DOCTOR, AGE, HOSPITAL, PATIENT, DATE, MEDICALRECORD,\nColor codes:PROBLEM, TREATMENT, TEST,\nDeid NER\nJohn Snow LABS\nSpark NLP Modules\nClinical\nEntity Recognition\nClinical\nEntity Linking\nAssertion Status\nRelation Extraction\nEntity Recognition\nInformation Extraction\nTheyme: Last week2904-2020\nSentiment Analysis\nDocument Classification\n40 units\nInsulin glargine\nat night EREQUENGY\nSuspect dlabetes SNOMED-CT: 67312700\nFever and sore throat -\\u003e PRESENT\nLisinopril 10 MG RaNorm:\n316151\nNo stomach pain\nHyponatremia\nICD-10:\nFather with Alzheim\nFAMIlY\nCAUSED BY\nSplit Text\nAlgorithms\nClean Text\nTransformers\nContent\n200+ Languages\nExtract Knowledge\nEntty Linker\n*Entity Disambiguator\n*Document Classifier\nContextual Parser\nSplit Text\nSentence Detector\n*Deep Sentence Detector\n*Tokenizer\n*\nnGram Generator\nAlgorithms\nDe-identify text\n• Structured Data\n* Unstructured Text\n* Obfuscator\n* Generalizer\nClean Medical Text\n• Spell Checking\n*Spell Correction\n*Normalizer\n* Stopword Cleaner\nMedical\nTransformers\nJSL-BERT-Clinical BioBERT\nClinicalBERT Glove-Med\nGloVe-ICD-O BlueBERT\nContent\nLinked Medical\nTerminologies\nSNOMED-сT CPT\nICD-10-см RxNorm\n[CD-10-PCS) ICD-O LOINC\n75+ Pretrained Models\nClinical:\nAnatomy:\nSigns, Symptoms, Treatments,\nOrgan, Subdivision, Cell, Structure\nProcedures, Tests, Labs, Sections\nOrganism, Tissue, Gene. Chemical\nSentence Detector\nDeep Sentence Detector\nTokenizer\nnGram Generator\nWord Segmentation\nUnderstand Grammar\nStemmer\n*Lemmatizer\n*\nPart of Speech\nTagger\nDependency Parser\nTranslation\nSpell Checking\nSpell Correction\nNormalizer\nStopword Cleaner\nSummarization\nFind in Text\nText Matcher\nRegex Matcher\n*Date Matcher\nChunker\n• Question Answering\nTrainable \\u0026 Tunable\nScalable to a Cluster\nFast Inference\nBERT ELMO GloVe\nALBERT XLNet USE\nSmall BERT ELECTRA\nTS NMT LaBSE\nPre-trained Models\n700+\nHardware Optimized\nPre-trained Pipelines\n400+\nCommunity\nClinical Grammar\nStemmer\n* Lemmatizer\n* Part of Spech Tagger\nDependency Parser\nFind\nin Text\n• Text Matcher\n* Regex Matcher\n* Date Matcher\nChunker\nDrugs:\nName, Dosage, Strength, Route,\nDurationFr\noFrequer\nFrequency\nPolsona, Adverse Effects\nDemographics:\nAge, Gender, Height, Weight, Race,\nEthinicity, Marital Status,\nVital Signs\nRisk Factors:\nSensitive Data:\nSmoking, Obesity, Diabetes,\nPatient Name, Address, Phone,\nHypertension, Substance Abuse\nEmail, Dates, Providers, Identifiers\nWord Segmentation\nSpärk ML\nLightPipeline\n(intel\nNVIDIA\nNLP\nSUMMIT\nTrainable \\u0026 Tunable Scalable to a Cluster\nFast Inference\nHardware Optimized\nCommunity\nSpärk Ml\nLightPipeline\n(intel\nnVIDIA\nNLP\nSÜMMIT\nTable 2: The most frequent 10 terms from the selected entity types predicted through parsing 100\narticles from CORD-19 dataset [2] with an NER model named jsl_ner_wip in Spark NLP. Getting\npredictions from the model, we can get some valuable information regarding the most frequent\ndisorders or symptoms mentioned in the papers or the most common vital and EKG findings without\nreading the paper. According to this table, the most common symptom is cough and inflammation\nwhile the most common drug ingredients mentioned is oseltamivir and antibiotics. We can also say\nthat cardiogenic oscillations and ventricular fibrillation are the common observations from EKGs\nwhile fever and hyphothermia are the most common vital signs.\nDisease Syndrome\nDisorder\nCommunicable\nDisease\nSymptom\nDrug\nIngredient\nProcedure\nVital Sign\nFindings\nEKG\nFindings\ninfectious diseases HIV\nsepsis\ninfluenza\nseptic shock\nasthma\npneumonia\nCOPD\ngastroenteritis\nviral infections\nSARS\ncough\noseltamivir\nresuscitation\nH1N1\ninflammation biological agents cardiac surgery\ntuberculosis\ncritically ill\nVLPs\ntracheostomy\ninfluenza\nnecrosis\nantibiotics\nCPR\nbleeding\nsaline\nvaccination\nhepatitis viruses\nlesion\nantiviral\nbronchoscopy\nmeasles\ncell swelling quercetin\nintubation\npandemic\ninfluenza\nhemorrhage NaCl\nseasonal\ninfluenza\ndiarrhea\nrabies\ntoxicity\nfever\nlow VT\nhypothermia\ncardiogenic oscillations\nhypoxia\nsignificant changes\nrespiratory failure CO reduces oxygen transport\nhypotension\nhypercapnia\nventricular fibrillation\nsignificant impedance increases\nventricular fibrillation\ntachypnea\ntransfection\nrespiratory distress pulseless electrical activity\nribavirin\nbronchoalveolar lavage hypoxaemia\nmildmoderate hypothermia\nNorwalk agent\nautopsy\npyrexia\ncardiogenic oscillations\nand clinical english model packages in the stanza python nlp library, arXiv\npreprint arXiv:2007.14640.\n[10] M. Neumann, D. King, I. Beltagy, W. Ammar, Scispacy: Fast and ro-\nbust models for biomedical natural language processing, arXiv preprint\narXiv:1902.07669.\n[11] V. Yadav, S. Bethard, A survey on recent advances in named entity recognition\nfrom deep learning models, arXiv preprint arXiv:1910.11470.\n[12] Ö. Uzuner, B. R. South, S. Shen, S. L. DuVall, 2010 i2b2/va challenge on\nconcepts, assertions, and relations in clinical text, Journal of the American\nMedical Informatics Association 18 (5) (2011) 552-556 .\n[13] D. Tzitzivacos, International classification of diseases 10th edition (icd-10)::\nmain article, CME: Your SA Journal of CPD 25 (1) (2007) 8-10.\n[14] Ö. Uzuner, Y. Luo, P. Szolovits, Evaluating the state-of-the-art in automatic\nde-identification, Journal of the American Medical Informatics Association\n14 (5) (2007) 550-563 .\n[15] S. Liu, B. Tang, Q. Chen, X. Wang, Effects of semantic features on ma-\nchine learning-based drug name recognition systems: word embeddings vs.\nmanually constructed dictionaries, Information 6 (4) (2015) 848-865 .\n[16] V. Kocaman, D. Talby, Biomedical named entity recognition at scale, arXiv\npreprint arXiv:2011.06315.\n8\n[17] J. P. Chiu, E. Nichols, Named entity recognition with bidirectional Istm-\ncnns, Transactions of the Association for Computational Linguistics 4 (2016)\n357-370 .\n[18] V. Kocaman, D. Talby, Improving clinical document understanding on covid-\n19 research with spark nlp, arXiv preprint arXiv:2012.04005.\n[19] J. S. Labs, Apache Spark NLP for Healthcare:\nLessons\nLearned\nBuilding\nReal-World\nHealthcare\nAI\nSys-\ntems,\nhttps://databricks.com/session_na20/\napache-spark-nlp-for-healthcare-lessons-learned-building-real-wo\n[Online; accessed 22-Jan-2021] (2021).\n[20] J. S. Labs, NLP Case Studies, https://www.johnsnowlabs.com/\nnlp-case-studies/, [Online; accessed 22-Jan-2021] (2021).\n[21] J. S. Labs, AI Case Studies, https://www.johnsnowlabs.com/\nai-case-studies/, [Online; accessed 22-Jan-2021] (2021).\n[22] X. Wang, Y. Zhang, X. Ren, Y. Zhang, M. Zitnik, J. Shang, C. Langlotz,\nJ. Han, Cross-type biomedical named entity recognition with deep multi-task\nlearning, Bioinformatics 35 (10) (2019) 1745-1752.\nRequired Metadata\nCurrent code version\nCurrent executable software version\nNr. Code\nmetadata description\nPlease fill in this column\nC1 Current code version\nv2.7.1\nC2\nPermanent link to code/repository used\nfor this code version\nhttps://github.com/JohnSnowLabs/spark-\nnlp\nC3\nPermanent link to Reproducible Cap-\nsule\nhttps://github.com/JohnSnowLabs/spark-\nnlp-workshop\nC4 Legal Code License\nC5 Code versioning system used\nC6 Software code languages, tools, and ser-\nApache-2.0 License\ngit, maven\nscala, python, java, R\nvices used\nC7 Compilation requirements, operating\njdk 8, spark\nenvironments \\u0026 dependencies\nC8 If available Link to developer documen-\nhttps://nlp.johnsnowlabs.com/api/\ntation/manual\nSupport email for questions\ninfo@johnsnowlabs.com\nTable 3: Code metadata (mandatory)\nNr. (Executable) software metadata de- Please fill in this column\nscription\nS1 Current software version\n2.7.1\nS2\nPermanent link to executables of this\nversion\nhttps://github.com/JohnSnowLabs/spark-\nnl\nS3\nPermanent link to Reproducible Cap-\nsule\nhttps://github.com/JohnSnowLabs/spark-\nnlp-workshop\nS4 Legal Software License\nApache-2.0 License\nS5\nComputing platforms/Operating Sys-\ntems\nLinux, Ubuntu, OSX, Microsoft Win-\ndows, Unix-like\nS6\nInstallation requirements \\u0026 dependen-\ncies\njdk 8, spark\nS7\nIf available, link to user manual - if\nformally published include a reference\nto the publication in the reference list\nhttps://nlp.johnsnowlabs.com/api/\nS8 Support email for questions\ninfo@johnsnowlabs.com\n10\n"
	text, err := yandexCloudApi.RecognizeTextFromPdf(pdfContent)
	if err != nil {
		log.Error(err)
		return err
	}
	log.Info(text)
	return nil
}
